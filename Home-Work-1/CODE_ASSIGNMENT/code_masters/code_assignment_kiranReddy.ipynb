{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0gFJNxnhpZoc"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from data_process import get_CIFAR10_data\n",
    "%matplotlib inline\n",
    "from save_submission import output_submission_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFpMITkVpZof"
   },
   "source": [
    "# Loading CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQhLz6_ypZoh"
   },
   "source": [
    "In the following cells we determine the number of images for each split and load the images.\n",
    "<br /> \n",
    "TRAIN_IMAGES + VAL_IMAGES = (0, 50000]\n",
    ", TEST_IMAGES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EdJkhInTpZoh"
   },
   "outputs": [],
   "source": [
    "# You can change these numbers for experimentation\n",
    "# For submission we will use the default values \n",
    "\n",
    "#Playing arounf with the values in-order to study the dataset\n",
    "# TRAIN_IMAGES = 4\n",
    "# VAL_IMAGES = 10\n",
    "\n",
    "\n",
    "TRAIN_IMAGES = 40000\n",
    "VAL_IMAGES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lYxkvXIrpZoi"
   },
   "outputs": [],
   "source": [
    "data = get_CIFAR10_data(TRAIN_IMAGES, VAL_IMAGES)\n",
    "X_train_CIFAR, y_train_CIFAR = data['X_train'], data['y_train']\n",
    "X_val_CIFAR, y_val_CIFAR = data['X_val'], data['y_val']\n",
    "X_test_CIFAR, y_test_CIFAR = data['X_test'], data['y_test']\n",
    "n_class_CIFAR = len(np.unique(y_test_CIFAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-7.18991250e+01 -8.72976000e+01 -8.12357000e+01 ...  2.67462500e+01\n",
      "     2.14346500e+01  1.76517250e+01]\n",
      "   [-1.14228675e+02 -1.29459550e+02 -1.12339025e+02 ... -7.25522500e+00\n",
      "    -1.05204500e+01 -7.31355000e+00]\n",
      "   [-1.04823175e+02 -1.12813825e+02 -8.06145500e+01 ... -1.13619750e+01\n",
      "    -8.75937500e+00 -1.97586000e+01]\n",
      "   ...\n",
      "   [ 8.13622000e+01  7.63019000e+01  7.40273750e+01 ...  3.55747000e+01\n",
      "    -6.88562250e+01 -7.26718250e+01]\n",
      "   [ 5.28395750e+01  4.74419750e+01  6.06504750e+01 ...  5.82546000e+01\n",
      "    -2.88197500e+01 -4.31803750e+01]\n",
      "   [ 4.91837000e+01  4.13473750e+01  5.20684000e+01 ...  8.89515250e+01\n",
      "     2.41888500e+01 -3.86372500e+00]]\n",
      "\n",
      "  [[-7.41391000e+01 -8.94913250e+01 -8.83168250e+01 ... -4.35872500e+00\n",
      "    -1.07493000e+01 -1.15151000e+01]\n",
      "   [-1.15307550e+02 -1.34451950e+02 -1.27177225e+02 ... -4.72118500e+01\n",
      "    -5.16138250e+01 -4.74037250e+01]\n",
      "   [-1.10622775e+02 -1.26470025e+02 -1.07078775e+02 ... -4.99957250e+01\n",
      "    -4.95833250e+01 -6.05901000e+01]\n",
      "   ...\n",
      "   [ 4.39784000e+01  2.91506750e+01  3.81308250e+01 ...  9.86915000e+00\n",
      "    -9.28604750e+01 -9.09623000e+01]\n",
      "   [ 1.25385000e+01 -1.66955000e+00  1.97332250e+01 ...  2.34545000e+01\n",
      "    -6.28382000e+01 -7.24307500e+01]\n",
      "   [ 1.69809000e+01  3.29777500e+00  1.61670500e+01 ...  5.80734500e+01\n",
      "    -7.82695000e+00 -3.40354500e+01]]\n",
      "\n",
      "  [[-6.95475250e+01 -8.68008750e+01 -8.95453500e+01 ... -2.43814250e+01\n",
      "    -2.99332000e+01 -2.88278500e+01]\n",
      "   [-1.11293350e+02 -1.30370175e+02 -1.31005450e+02 ... -7.58616750e+01\n",
      "    -8.04553250e+01 -7.33843250e+01]\n",
      "   [-1.09164900e+02 -1.28921300e+02 -1.21412900e+02 ... -7.92062250e+01\n",
      "    -7.89833500e+01 -8.71575000e+01]\n",
      "   ...\n",
      "   [-1.81351250e+01 -7.78296500e+01 -8.47434000e+01 ... -4.10021750e+01\n",
      "    -1.04880800e+02 -9.32244750e+01]\n",
      "   [-1.86461500e+01 -7.07085750e+01 -8.21866750e+01 ... -1.84496000e+01\n",
      "    -7.89046500e+01 -7.97609750e+01]\n",
      "   [ 5.67225000e-01 -1.99450250e+01 -2.69526250e+01 ...  2.59582750e+01\n",
      "    -3.01040000e+01 -4.25743000e+01]]]\n",
      "\n",
      "\n",
      " [[[ 2.31008750e+01 -4.29760000e+00 -2.62357000e+01 ... -4.02537500e+01\n",
      "    -4.35653500e+01 -5.13482750e+01]\n",
      "   [ 9.77132500e+00  1.55404500e+01 -5.33902500e+00 ... -3.42552250e+01\n",
      "    -5.25204500e+01 -5.83135500e+01]\n",
      "   [ 1.01768250e+01  1.01861750e+01 -1.46145500e+01 ... -5.03619750e+01\n",
      "    -6.07593750e+01 -6.17586000e+01]\n",
      "   ...\n",
      "   [ 4.83622000e+01  3.13019000e+01  3.00273750e+01 ... -8.24253000e+01\n",
      "    -6.38562250e+01 -3.26718250e+01]\n",
      "   [ 3.78395750e+01  3.04419750e+01  3.36504750e+01 ... -2.27454000e+01\n",
      "    -2.81975000e+00  4.81962500e+00]\n",
      "   [ 3.51837000e+01  3.13473750e+01  3.60684000e+01 ...  1.59515250e+01\n",
      "     1.61888500e+01  1.61362750e+01]]\n",
      "\n",
      "  [[ 4.08609000e+01  1.50867500e+00 -3.23168250e+01 ... -4.13587250e+01\n",
      "    -4.57493000e+01 -5.45151000e+01]\n",
      "   [ 2.46924500e+01  1.85480500e+01 -1.01772250e+01 ... -3.62118500e+01\n",
      "    -5.46138250e+01 -6.14037250e+01]\n",
      "   [ 2.03772250e+01  1.25299750e+01 -1.90787750e+01 ... -5.19957250e+01\n",
      "    -6.35833250e+01 -6.45901000e+01]\n",
      "   ...\n",
      "   [ 4.09784000e+01  3.01506750e+01  3.71308250e+01 ... -8.91308500e+01\n",
      "    -7.08604750e+01 -4.19623000e+01]\n",
      "   [ 2.75385000e+01  2.73304500e+01  3.67332250e+01 ... -3.15455000e+01\n",
      "    -1.08382000e+01 -4.43075000e+00]\n",
      "   [ 2.09809000e+01  2.22977750e+01  3.01670500e+01 ...  7.07345000e+00\n",
      "     8.17305000e+00  6.96455000e+00]]\n",
      "\n",
      "  [[ 5.44524750e+01  4.19912500e+00 -3.75453500e+01 ... -6.13814250e+01\n",
      "    -6.09332000e+01 -6.18278500e+01]\n",
      "   [ 3.77066500e+01  2.36298250e+01 -1.30054500e+01 ... -5.28616750e+01\n",
      "    -6.84553250e+01 -6.93843250e+01]\n",
      "   [ 3.38351000e+01  2.00787000e+01 -1.74129000e+01 ... -6.52062250e+01\n",
      "    -7.39833500e+01 -7.41575000e+01]\n",
      "   ...\n",
      "   [ 5.18648750e+01  4.81703500e+01  5.92566000e+01 ... -7.50021750e+01\n",
      "    -5.48808000e+01 -2.22244750e+01]\n",
      "   [ 1.33538500e+01  1.72914250e+01  2.98133250e+01 ... -1.64496000e+01\n",
      "     7.09535000e+00  1.72390250e+01]\n",
      "   [ 4.56722500e+00  8.05497500e+00  1.90473750e+01 ...  2.49582750e+01\n",
      "     2.78960000e+01  2.94257000e+01]]]\n",
      "\n",
      "\n",
      " [[[ 1.24100875e+02  1.22702400e+02  1.21764300e+02 ...  1.21746250e+02\n",
      "     1.22434650e+02  1.22651725e+02]\n",
      "   [ 1.24771325e+02  1.25540450e+02  1.24660975e+02 ...  1.24744775e+02\n",
      "     1.25479550e+02  1.25686450e+02]\n",
      "   [ 1.25176825e+02  1.25186175e+02  1.24385450e+02 ...  1.24638025e+02\n",
      "     1.25240625e+02  1.25241400e+02]\n",
      "   ...\n",
      "   [-1.36378000e+01 -1.36981000e+01 -1.89726250e+01 ... -5.24253000e+01\n",
      "    -5.28562250e+01 -5.36718250e+01]\n",
      "   [-1.61604250e+01 -2.15580250e+01 -2.63495250e+01 ... -5.77454000e+01\n",
      "    -5.58197500e+01 -4.81803750e+01]\n",
      "   [-2.18163000e+01 -2.76526250e+01 -3.19316000e+01 ... -4.90484750e+01\n",
      "    -4.78111500e+01 -4.68637250e+01]]\n",
      "\n",
      "  [[ 1.18860900e+02  1.17508675e+02  1.16683175e+02 ...  1.16641275e+02\n",
      "     1.17250700e+02  1.17484900e+02]\n",
      "   [ 1.19692450e+02  1.20548050e+02  1.19822775e+02 ...  1.19788150e+02\n",
      "     1.20386175e+02  1.20596275e+02]\n",
      "   [ 1.20377225e+02  1.20529975e+02  1.19921225e+02 ...  1.20004275e+02\n",
      "     1.20416675e+02  1.20409900e+02]\n",
      "   ...\n",
      "   [-6.02160000e+00 -5.84932500e+00 -1.08691750e+01 ... -4.21308500e+01\n",
      "    -4.38604750e+01 -4.49623000e+01]\n",
      "   [-8.46150000e+00 -1.36695500e+01 -1.82667750e+01 ... -4.95455000e+01\n",
      "    -4.88382000e+01 -4.14307500e+01]\n",
      "   [-1.40191000e+01 -1.97022250e+01 -2.38329500e+01 ... -4.09265500e+01\n",
      "    -4.08269500e+01 -4.00354500e+01]]\n",
      "\n",
      "  [[ 1.22452475e+02  1.21199125e+02  1.20454650e+02 ...  1.20618575e+02\n",
      "     1.21066800e+02  1.21172150e+02]\n",
      "   [ 1.23706650e+02  1.24629825e+02  1.23994550e+02 ...  1.24138325e+02\n",
      "     1.24544675e+02  1.24615675e+02]\n",
      "   [ 1.24835100e+02  1.25078700e+02  1.24587100e+02 ...  1.24793775e+02\n",
      "     1.25016650e+02  1.24842500e+02]\n",
      "   ...\n",
      "   [-2.13512500e+00 -8.29650000e-01 -4.74340000e+00 ... -3.10021750e+01\n",
      "    -3.28808000e+01 -3.42244750e+01]\n",
      "   [-4.64615000e+00 -8.70857500e+00 -1.41866750e+01 ... -3.94496000e+01\n",
      "    -3.79046500e+01 -3.17609750e+01]\n",
      "   [-1.04327750e+01 -1.59450250e+01 -1.99526250e+01 ... -3.10417250e+01\n",
      "    -3.11040000e+01 -3.05743000e+01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 3.61008750e+01  3.37024000e+01  1.97643000e+01 ... -2.72537500e+01\n",
      "     2.04346500e+01 -1.13482750e+01]\n",
      "   [ 6.17713250e+01  7.65404500e+01  8.26609750e+01 ... -3.42552250e+01\n",
      "     5.47955000e+00 -6.31355000e+00]\n",
      "   [ 8.01768250e+01  4.91861750e+01  8.03854500e+01 ... -4.23619750e+01\n",
      "    -1.47593750e+01  8.24140000e+00]\n",
      "   ...\n",
      "   [ 3.53622000e+01  2.93019000e+01  2.90273750e+01 ...  2.15747000e+01\n",
      "     1.71437750e+01  8.32817500e+00]\n",
      "   [ 3.28395750e+01  3.04419750e+01  3.06504750e+01 ...  2.12546000e+01\n",
      "     2.41802500e+01  1.68196250e+01]\n",
      "   [ 2.81837000e+01  1.83473750e+01  2.20684000e+01 ...  3.69515250e+01\n",
      "     4.71888500e+01  3.41362750e+01]]\n",
      "\n",
      "  [[ 4.86090000e+00 -1.49132500e+00 -2.23168250e+01 ... -6.53587250e+01\n",
      "    -3.07493000e+01 -5.65151000e+01]\n",
      "   [ 2.96924500e+01  2.65480500e+01  1.48227750e+01 ... -7.32118500e+01\n",
      "    -4.46138250e+01 -5.24037250e+01]\n",
      "   [ 3.03772250e+01 -7.47002500e+00  1.59212250e+01 ... -8.19957250e+01\n",
      "    -6.05833250e+01 -3.95901000e+01]\n",
      "   ...\n",
      "   [-3.02160000e+00 -8.84932500e+00 -8.86917500e+00 ... -8.13085000e+00\n",
      "    -1.18604750e+01 -1.89623000e+01]\n",
      "   [-4.46150000e+00 -5.66955000e+00 -5.26677500e+00 ... -6.54550000e+00\n",
      "    -3.83820000e+00 -1.14307500e+01]\n",
      "   [-7.01910000e+00 -1.47022250e+01 -9.83295000e+00 ...  1.00734500e+01\n",
      "     2.01730500e+01  7.96455000e+00]]\n",
      "\n",
      "  [[-2.25475250e+01 -3.08008750e+01 -4.35453500e+01 ... -6.93814250e+01\n",
      "    -3.29332000e+01 -6.28278500e+01]\n",
      "   [-4.29335000e+00 -5.37017500e+00 -6.00545000e+00 ... -7.88616750e+01\n",
      "    -4.94553250e+01 -5.83843250e+01]\n",
      "   [-1.64900000e-01 -3.69213000e+01 -9.41290000e+00 ... -8.92062250e+01\n",
      "    -6.89833500e+01 -4.51575000e+01]\n",
      "   ...\n",
      "   [ 2.86487500e+00 -8.29650000e-01 -1.74340000e+00 ...  9.97825000e-01\n",
      "    -2.88080000e+00 -1.12244750e+01]\n",
      "   [ 5.35385000e+00  3.29142500e+00  8.13325000e-01 ...  1.55040000e+00\n",
      "     4.09535000e+00 -3.76097500e+00]\n",
      "   [ 5.56722500e+00 -5.94502500e+00 -4.95262500e+00 ...  1.79582750e+01\n",
      "     2.78960000e+01  1.54257000e+01]]]\n",
      "\n",
      "\n",
      " [[[-8.58991250e+01 -8.42976000e+01 -8.52357000e+01 ... -8.32537500e+01\n",
      "    -8.25653500e+01 -8.33482750e+01]\n",
      "   [-8.42286750e+01 -8.24595500e+01 -8.33390250e+01 ... -7.92552250e+01\n",
      "    -7.95204500e+01 -8.23135500e+01]\n",
      "   [-8.38231750e+01 -8.18138250e+01 -8.26145500e+01 ... -7.93619750e+01\n",
      "    -7.77593750e+01 -8.07586000e+01]\n",
      "   ...\n",
      "   [-3.06378000e+01 -6.46981000e+01 -7.39726250e+01 ... -9.74253000e+01\n",
      "    -5.88562250e+01 -1.67182500e+00]\n",
      "   [-8.81604250e+01 -8.65580250e+01 -4.53495250e+01 ... -8.37454000e+01\n",
      "    -4.88197500e+01 -2.11803750e+01]\n",
      "   [-9.68163000e+01 -8.36526250e+01 -6.59316000e+01 ... -7.80484750e+01\n",
      "    -5.08111500e+01 -6.48637250e+01]]\n",
      "\n",
      "  [[-6.01391000e+01 -5.74913250e+01 -5.63168250e+01 ... -5.33587250e+01\n",
      "    -5.47493000e+01 -5.75151000e+01]\n",
      "   [-5.73075500e+01 -5.44519500e+01 -5.31772250e+01 ... -5.22118500e+01\n",
      "    -5.16138250e+01 -5.24037250e+01]\n",
      "   [-5.46227750e+01 -5.14700250e+01 -5.00787750e+01 ... -5.09957250e+01\n",
      "    -4.75833250e+01 -4.95901000e+01]\n",
      "   ...\n",
      "   [-4.30216000e+01 -6.98493250e+01 -8.78691750e+01 ... -6.61308500e+01\n",
      "    -5.98604750e+01 -6.19623000e+01]\n",
      "   [-8.84615000e+01 -8.96695500e+01 -6.62667750e+01 ... -6.65455000e+01\n",
      "    -5.98382000e+01 -5.64307500e+01]\n",
      "   [-6.80191000e+01 -6.57022250e+01 -6.58329500e+01 ... -7.29265500e+01\n",
      "    -6.28269500e+01 -7.30354500e+01]]\n",
      "\n",
      "  [[-5.54752500e+00 -1.80087500e+00  4.54650000e-01 ...  6.61857500e+00\n",
      "     4.06680000e+00  1.17215000e+00]\n",
      "   [-1.29335000e+00  2.62982500e+00  5.99455000e+00 ...  8.13832500e+00\n",
      "     8.54467500e+00  7.61567500e+00]\n",
      "   [ 2.83510000e+00  8.07870000e+00  1.15871000e+01 ...  8.79377500e+00\n",
      "     1.40166500e+01  1.48425000e+01]\n",
      "   ...\n",
      "   [-3.71351250e+01 -6.88296500e+01 -8.97434000e+01 ... -9.30021750e+01\n",
      "    -8.78808000e+01 -7.32244750e+01]\n",
      "   [-8.26461500e+01 -9.17085750e+01 -7.91866750e+01 ... -8.44496000e+01\n",
      "    -8.29046500e+01 -7.37609750e+01]\n",
      "   [-9.24327750e+01 -8.29450250e+01 -7.99526250e+01 ... -8.40417250e+01\n",
      "    -8.01040000e+01 -9.05743000e+01]]]\n",
      "\n",
      "\n",
      " [[[ 1.04100875e+02  1.08702400e+02  1.07764300e+02 ...  9.37462500e+01\n",
      "     9.74346500e+01  9.76517250e+01]\n",
      "   [ 1.18771325e+02  1.21540450e+02  1.21660975e+02 ...  9.87447750e+01\n",
      "     1.01479550e+02  1.02686450e+02]\n",
      "   [ 1.11176825e+02  1.14186175e+02  1.15385450e+02 ...  1.01638025e+02\n",
      "     1.03240625e+02  1.04241400e+02]\n",
      "   ...\n",
      "   [-4.56378000e+01 -3.96981000e+01 -4.09726250e+01 ...  4.25747000e+01\n",
      "     4.31437750e+01  3.93281750e+01]\n",
      "   [-4.81604250e+01 -5.65580250e+01 -5.83495250e+01 ...  4.42546000e+01\n",
      "     3.71802500e+01  3.48196250e+01]\n",
      "   [-8.18163000e+01 -8.16526250e+01 -7.49316000e+01 ...  4.79515250e+01\n",
      "     4.11888500e+01  3.61362750e+01]]\n",
      "\n",
      "  [[ 1.15860900e+02  1.15508675e+02  1.14683175e+02 ...  1.14641275e+02\n",
      "     1.15250700e+02  1.16484900e+02]\n",
      "   [ 1.19692450e+02  1.18548050e+02  1.18822775e+02 ...  1.19788150e+02\n",
      "     1.20386175e+02  1.20596275e+02]\n",
      "   [ 1.15377225e+02  1.14529975e+02  1.13921225e+02 ...  1.19004275e+02\n",
      "     1.19416675e+02  1.19409900e+02]\n",
      "   ...\n",
      "   [-8.02160000e+00 -8.49325000e-01  1.30825000e-01 ...  4.38691500e+01\n",
      "     4.41395250e+01  4.10377000e+01]\n",
      "   [-7.46150000e+00 -1.66695500e+01 -1.92667750e+01 ...  4.74545000e+01\n",
      "     3.91618000e+01  3.85692500e+01]\n",
      "   [-4.00191000e+01 -4.27022250e+01 -3.78329500e+01 ...  5.30734500e+01\n",
      "     4.61730500e+01  4.29645500e+01]]\n",
      "\n",
      "  [[ 1.19452475e+02  1.19199125e+02  1.18454650e+02 ...  1.19618575e+02\n",
      "     1.20066800e+02  1.20172150e+02]\n",
      "   [ 1.23706650e+02  1.24629825e+02  1.23994550e+02 ...  1.24138325e+02\n",
      "     1.24544675e+02  1.24615675e+02]\n",
      "   [ 1.23835100e+02  1.23078700e+02  1.22587100e+02 ...  1.21793775e+02\n",
      "     1.23016650e+02  1.22842500e+02]\n",
      "   ...\n",
      "   [ 6.18648750e+01  6.61703500e+01  6.42566000e+01 ...  5.69978250e+01\n",
      "     5.81192000e+01  5.57755250e+01]\n",
      "   [ 6.13538500e+01  5.02914250e+01  4.58133250e+01 ...  6.15504000e+01\n",
      "     5.40953500e+01  5.52390250e+01]\n",
      "   [ 2.65672250e+01  2.30549750e+01  2.70473750e+01 ...  6.79582750e+01\n",
      "     6.08960000e+01  5.94257000e+01]]]]\n",
      "(40000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_CIFAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_CIFAR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8paIOoaBpZoi"
   },
   "source": [
    "Convert the sets of images from dimensions of **(N, 3, 32, 32) -> (N, 3072)** where N is the number of images so that each **3x32x32** image is represented by a single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "hsgufbOhpZoj"
   },
   "outputs": [],
   "source": [
    "X_train_CIFAR = np.reshape(X_train_CIFAR, (X_train_CIFAR.shape[0], -1))\n",
    "X_val_CIFAR = np.reshape(X_val_CIFAR, (X_val_CIFAR.shape[0], -1))\n",
    "X_test_CIFAR = np.reshape(X_test_CIFAR, (X_test_CIFAR.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r91wHO51pZoj"
   },
   "source": [
    "# Get Accuracy\n",
    "This function computes how well your model performs using accuracy as a metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "qDRrRQAlpZok"
   },
   "outputs": [],
   "source": [
    "def get_acc(pred, y_test):\n",
    "    return np.sum(y_test==pred)/len(y_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjEyGAXrpZol"
   },
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i4BlNEwpZol"
   },
   "source": [
    "Perceptron has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - controls how much we change the current weights of the classifier during each update. We set it at a default value of 0.5, but you should experiment with different values. We recommend changing the learning rate by factors of 10 and observing how the performance of the classifier changes. You should also try adding a **decay** which slowly reduces the learning rate over each epoch.\n",
    "- **Number of Epochs** - An epoch is a complete iterative pass over all of the data in the dataset. During an epoch we predict a label using the classifier and then update the weights of the classifier according the perceptron update rule for each sample in the training set. You should try different values for the number of training epochs and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCB44zoIpZom"
   },
   "source": [
    "\n",
    "The following code: \n",
    "- Creates an instance of the Perceptron classifier class \n",
    "- The train function of the Perceptron class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pQMfcXvpZom"
   },
   "source": [
    "# Model Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "xHFooAwLpZom"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, n_class: int, lr: float, epochs: int):\n",
    "        \"\"\"Initialize a new classifier.\n",
    "        Parameters:\n",
    "            n_class: the number of classes\n",
    "            lr: the learning rate\n",
    "            epochs: the number of epochs to train for\n",
    "        \"\"\"\n",
    "        self.w = None\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.n_class = n_class\n",
    "        self.bias=None\n",
    "        self.activation_func=self._unit_step_func\n",
    "\n",
    "\n",
    "    def train(self, X_train: np.ndarray, y_train: np.ndarray):\n",
    "        \"\"\"Train the classifier.\n",
    "        Use the perceptron update rule as introduced in Lecture 3.\n",
    "        Parameters:\n",
    "            X_train: a number array of shape (N, D) containing training data;\n",
    "                N examples with D dimensions\n",
    "            y_train: a numpy array of shape (N,) containing training labels\n",
    "        \"\"\"\n",
    "        N, D = X_train.shape\n",
    "        self.w = np.random.randn(self.n_class, D)\n",
    "        self.bias=0\n",
    "        ###### YOUR CODE STARTS HERE ######\n",
    "        y_=np.array([1 if i>0 else 0 for i in y_train])\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X_train):\n",
    "                l_o=np.dot(x_i, self.w)+self.bias\n",
    "                y_predicted=self.activation_func(l_o)\n",
    "                update=self.lr*(y_[idx]-y_predicted)\n",
    "                self.weights+=update+x_i\n",
    "                self.bias+=update\n",
    "        ###### YOUR CODE ENDS HERE ######\n",
    "\n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Use the trained weights to predict labels for test data points.\n",
    "        Parameters:\n",
    "            X_test: a numpy array of shape (N, D) containing testing data;\n",
    "                N examples with D dimensions\n",
    "        Returns:\n",
    "            predicted labels for the data in X_test; a 1-dimensional array of\n",
    "                length N, where each element is an integer giving the predicted\n",
    "                class.\n",
    "        \"\"\"\n",
    "        N, D = X_test.shape\n",
    "        y_test = np.zeros(N)\n",
    "        ###### YOUR CODE STARTS HERE ######\n",
    "        l_o=np.dot(X_test, self.w)+self.bias\n",
    "        y_test = self.activation_func(l_o)\n",
    "\n",
    "        \n",
    "        ###### YOUR CODE ENDS HERE ######\n",
    "        return y_test\n",
    "\n",
    "    def _unit_step_func(self, x):\n",
    "        return np.where(x>=0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tjc80ISp_bYK"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_14_VVHhpZon"
   },
   "source": [
    "## Train Perceptron on CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "collapsed": true,
    "id": "7DG8rY9ApZon",
    "outputId": "20adac9b-2017-4fca-da82-76d7a041b26c"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Perceptron' object has no attribute 'n_iters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3979839743.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpercept_CIFAR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_class_CIFAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpercept_CIFAR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_CIFAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_CIFAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3608788855.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m###### YOUR CODE STARTS HERE ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0my_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0ml_o\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Perceptron' object has no attribute 'n_iters'"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 50\n",
    "n_class_CIFAR = 10\n",
    "\n",
    "percept_CIFAR = Perceptron(n_class_CIFAR, lr, n_epochs)\n",
    "percept_CIFAR.train(X_train_CIFAR, y_train_CIFAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "id": "3A_8NAEJpZon"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (40000,3072) and (10,3072) not aligned: 3072 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/1903334046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_percept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpercept_CIFAR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_CIFAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The training accuracy is given by: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_percept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_CIFAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3608788855.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m###### YOUR CODE STARTS HERE ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0ml_o\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Into2DeepLearning/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (40000,3072) and (10,3072) not aligned: 3072 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_CIFAR.predict(X_train_CIFAR)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_CIFAR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPoG32Y0pZon"
   },
   "source": [
    "### Validate Perceptron on CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "id": "INpI-9fVpZon"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10000,3072) and (10,3072) not aligned: 3072 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3473324202.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_percept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpercept_CIFAR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_CIFAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The validation accuracy is given by: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_percept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_CIFAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3608788855.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m###### YOUR CODE STARTS HERE ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0ml_o\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Into2DeepLearning/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10000,3072) and (10,3072) not aligned: 3072 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_CIFAR.predict(X_val_CIFAR)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_CIFAR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LitUu8g0pZoo"
   },
   "source": [
    "### Test Perceptron on CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "id": "CLB5yeeTpZoo"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10000,3072) and (10,3072) not aligned: 3072 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/2133235364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_percept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpercept_CIFAR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_CIFAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The testing accuracy is given by: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_percept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_CIFAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3608788855.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m###### YOUR CODE STARTS HERE ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0ml_o\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Into2DeepLearning/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10000,3072) and (10,3072) not aligned: 3072 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_CIFAR.predict(X_test_CIFAR)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_CIFAR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "id": "c1OHdRVepZoo"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10000,3072) and (10,3072) not aligned: 3072 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/4089202621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_submission_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/Logistic_submission_CIFAR.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercept_CIFAR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_CIFAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3608788855.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m###### YOUR CODE STARTS HERE ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0ml_o\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Into2DeepLearning/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10000,3072) and (10,3072) not aligned: 3072 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "output_submission_csv('output/Logistic_submission_CIFAR.csv', percept_CIFAR.predict(X_test_CIFAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_m0DUX0FpZoo"
   },
   "source": [
    "# Logistic Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4y4gKDvpZop"
   },
   "source": [
    "The Logistic Classifier has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
    "- **Number of Epochs** - As described for perceptron.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeyJ7sYNpZop"
   },
   "source": [
    "\n",
    "The following code: \n",
    "- Creates an instance of the Logistic classifier class \n",
    "- The train function of the Logistic class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "7ytp9mU2pZop"
   },
   "outputs": [],
   "source": [
    "\"\"\"Logistic regression model.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from numpy import log, dot\n",
    "import math\n",
    "\n",
    "\n",
    "class Logistic:\n",
    "    def __init__(self, lr: float, epochs: int):\n",
    "        \"\"\"Initialize a new classifier.\n",
    "        Parameters:\n",
    "            lr: the learning rate\n",
    "            epochs: the number of epochs to train for\n",
    "        \"\"\"\n",
    "        self.w = 1\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.threshold = 0.5\n",
    "\n",
    "    def sigmoid(self, z: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Sigmoid function.\n",
    "        Parameters:\n",
    "            z: the input\n",
    "        Returns:\n",
    "            the sigmoid of the input\n",
    "        \"\"\"\n",
    "        ##### YOUR CODE STARTS HERE #####\n",
    "        ret = 1/(1+np.exp(-z))\n",
    "        \n",
    "        ##### YOUR CODE ENDS HERE #####\n",
    "        return ret\n",
    "\n",
    "    def cost_function(self, X, y, weights):\n",
    "        z=dot(X, weights)\n",
    "        predict_1 = y * log(self.sigmoid(z))\n",
    "        predict_0 = (1-y)* log(1-self.sigmoid(z))\n",
    "        return -sum(predict_1 + predict_0)/ len(X)\n",
    "\n",
    "    def train(self, X_train: np.ndarray, y_train: np.ndarray):\n",
    "        \"\"\"Train the classifier.\n",
    "        Use the logistic regression update rule as introduced in lecture.\n",
    "        Parameters:\n",
    "            X_train: a numpy array of shape (N, D) containing training data;\n",
    "                N examples with D dimensions\n",
    "            y_train: a numpy array of shape (N,) containing training labels\n",
    "        \"\"\"\n",
    "        N, D = X_train.shape\n",
    "        loss=[]\n",
    "        w=np.random.randn(X_train.shape[1])\n",
    "        #self.w = np.random.randn(1, D)\n",
    "        N=len(X_train)\n",
    "\n",
    "        ##### YOUR CODE STARTS HERE #####\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            y_hat=self.sigmoid(dot(X_train, w))\n",
    "            w-=self.lr*dot(X_train.T, y_hat-y_train)/N\n",
    "            loss.append(self.cost_function(X_train, y_train, w))\n",
    "\n",
    "        self.w=w\n",
    "        self.loss=loss\n",
    "            \n",
    "        ##### YOUR CODE ENDS HERE #####\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Use the trained weights to predict labels for test data points.\n",
    "        Parameters:\n",
    "            X_test: a numpy array of shape (N, D) containing testing data;\n",
    "                N examples with D dimensions\n",
    "        Returns:\n",
    "            predicted labels for the data in X_test; a 1-dimensional array of\n",
    "                length N, where each element is an integer giving the predicted\n",
    "                class.\n",
    "        \"\"\"\n",
    "        N, D = X_test.shape\n",
    "        y_test = np.zeros(N)\n",
    "        ##### YOUR CODE STARTS HERE #####\n",
    "        z=dot(X_test, self.w)\n",
    "        y_test=[1 if i >0.7 else 0 for i in self.sigmoid(z)]\n",
    "        ##### YOUR CODE ENDS HERE #####\n",
    "        return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d2rj1rDpZoq"
   },
   "source": [
    "### Training Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50i_5rtTpZoq",
    "outputId": "7d98f299-6d85-4d1a-f485-877b94c74361"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3369660254.py:28: RuntimeWarning: overflow encountered in exp\n",
      "  ret = 1/(1+np.exp(-z))\n",
      "/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3369660254.py:35: RuntimeWarning: divide by zero encountered in log\n",
      "  predict_1 = y * log(self.sigmoid(z))\n",
      "/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3369660254.py:35: RuntimeWarning: invalid value encountered in multiply\n",
      "  predict_1 = y * log(self.sigmoid(z))\n",
      "/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3369660254.py:36: RuntimeWarning: divide by zero encountered in log\n",
      "  predict_0 = (1-y)* log(1-self.sigmoid(z))\n",
      "/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3369660254.py:36: RuntimeWarning: invalid value encountered in multiply\n",
      "  predict_0 = (1-y)* log(1-self.sigmoid(z))\n",
      "/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3369660254.py:37: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -sum(predict_1 + predict_0)/ len(X)\n"
     ]
    }
   ],
   "source": [
    "learning_rate =0.6\n",
    "n_epochs =50\n",
    "\n",
    "lr = Logistic(learning_rate, n_epochs)\n",
    "lr.train(X_train_CIFAR, y_train_CIFAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1lLs2WDpZoq",
    "outputId": "3eec86b5-f676-4b91-8415-04e37b6eaa27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 12.140000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3369660254.py:28: RuntimeWarning: overflow encountered in exp\n",
      "  ret = 1/(1+np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_train_CIFAR)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_lr, y_train_CIFAR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUausyFqpZoq"
   },
   "source": [
    "### Validate Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRdo75_FpZoq",
    "outputId": "1ac0d28b-3766-4f6e-9009-520125237015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 12.170000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3369660254.py:28: RuntimeWarning: overflow encountered in exp\n",
      "  ret = 1/(1+np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_val_CIFAR)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_lr, y_val_CIFAR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWgfQuZypZoq"
   },
   "source": [
    "### Test Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiCWJRAypZor",
    "outputId": "5433eab5-a6f5-4f7d-cd64-0a0066ee338e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 12.430000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fw/cxj36c7j5t9g1vd7yw1sdtxh0000gn/T/ipykernel_8533/3369660254.py:28: RuntimeWarning: overflow encountered in exp\n",
      "  ret = 1/(1+np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_test_CIFAR)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_lr, y_test_CIFAR)))\n",
    "output_submission_csv('output/Logistic_submission_CIFAR.csv', lr.predict(X_test_CIFAR))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "code_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
